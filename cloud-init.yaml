#cloud-config
package_update: true
package_upgrade: true
packages:
  - ca-certificates
  - curl
  - gnupg
  - lsb-release

runcmd:
  # Add Docker's official GPG key:
  - apt-get update
  - install -m 0755 -d /etc/apt/keyrings
  - curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --yes --dearmor -o /etc/apt/keyrings/docker.gpg
  - sudo chmod a+r /etc/apt/keyrings/docker.gpg

  # Add the repository to Apt sources:
  - |
      bash -c 'echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
      https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo $${UBUNTU_CODENAME:-$VERSION_CODENAME}) stable" \
      > /etc/apt/sources.list.d/docker.list'
  - apt-get update

  # Install and start docker
  - apt-get install -y docker-ce docker-compose docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
  - systemctl start docker

  # Add airflow user
  - groupadd -f docker
  - adduser --disabled-password --gecos "" airflow && usermod -aG docker airflow

  # Setup Airflow dir
  - mkdir -p /opt/airflow
  - mkdir -p /opt/airflow/dags
  - chown -R airflow:airflow /opt/airflow

  # Make the dir for dbt
  - mkdir -p /opt/airflow/dbt
  - chown -R airflow:airflow /opt/airflow/dbt

  # Wait for docker to be ready
  - until docker info >/dev/null 2>&1; do echo "Waiting for Docker..."; sleep 3; done
  - docker pull ghcr.io/dbt-labs/dbt-postgres:1.9.latest

  # Install PostgreSQL client
  - wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | tee /etc/apt/trusted.gpg.d/postgresql.asc > /dev/null
  - sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
  - apt-get update
  - apt-get -y install postgresql-client-17

  # Config Airflow
  - export AIRFLOW__SECRETS__BACKEND=airflow.providers.amazon.aws.secrets.systems_manager.SystemsManagerParameterStoreBackend
  - export AIRFLOW__SECRETS__BACKEND_KWARGS='{"variables_prefix":"/airflow/variables", "connections_prefix":"/airflow/connections"}'
  - export AIRFLOW__CORE__DAGS_FOLDER=s3://${airflow_dags} 

  - cd /opt/airflow
  - sudo curl -LfO https://airflow.apache.org/docs/apache-airflow/3.1.0/docker-compose.yaml
  - echo "AIRFLOW_UID=$(id -u airflow)" | sudo tee .env
  - echo "_AIRFLOW_WWW_USER_USERNAME=${airflow_username}" | tee -a .env
  - echo "_AIRFLOW_WWW_USER_PASSWORD=${airflow_password}" | tee -a .env
  - chown airflow:airflow .env
  - docker compose pull
  - sudo -u airflow -H bash -c "docker compose up"

final_message: "The Airflow EC2 instance is ready."
