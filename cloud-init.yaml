#cloud-config
package_update: true
package_upgrade: true
packages:
  - ca-certificates
  - curl
  - gnupg
  - lsb-release

runcmd:
  # Add Docker's official GPG key:
  - sudo apt-get update
  - sudo install -m 0755 -d /etc/apt/keyrings
  - curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --yes --dearmor -o /etc/apt/keyrings/docker.gpg
  - sudo chmod a+r /etc/apt/keyrings/docker.gpg

  # Add the repository to Apt sources:
  - |
      sudo bash -c 'echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
      https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo $${UBUNTU_CODENAME:-$VERSION_CODENAME}) stable" \
      > /etc/apt/sources.list.d/docker.list'
  - sudo apt-get update

  # Install everything docker & start it
  - sudo apt-get install -y docker-ce docker-compose docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
  - sudo systemctl start docker

  # Add airflow user
  - sudo groupadd -f docker
  - sudo adduser --disabled-password --gecos "" airflow && sudo usermod -aG docker airflow

  # Setup Airflow dir
  - sudo mkdir -p /opt/airflow
  - sudo mkdir -p /opt/airflow/dags
  - sudo chown -R airflow:airflow /opt/airflow

  # Make the dir for dbt
  - sudo mkdir -p /opt/airflow/dbt
  - sudo chown -R airflow:airflow /opt/airflow/dbt

  # Wait for docker to be ready
  - until sudo docker info >/dev/null 2>&1; do echo "Waiting for Docker..."; sleep 3; done
  - sudo docker pull ghcr.io/dbt-labs/dbt-postgres:1.9.latest

  # Create the 'main' database
  - |
    sudo -u postgres psql -h ${rds_endpoint} -U ${rds_username} -c "CREATE DATABASE main;"

  - |
    sudo bash -c 'cat << EOF > /opt/airflow/dbt/profiles.yml
    default:
      target: dev
      outputs:
        dev:
          type: postgres
          host: ${rds_endpoint}
          user: ${rds_username}
          password: ${rds_password}
          port: 5432
          dbname: main
          schema: public
    EOF'  

  # Add initial DBT dag
  - | 
    sudo bash -c 'cat << EOF > /opt/airflow/dags/dbt_runs.py
    from airflow import DAG
    from datetime import datetime
    from airflow.providers.docker.operators.docker import DockerOperator

    START_DATE = datetime(2025, 1, 1)

    with DAG(
        dag_id="dbt_runs",
        start_date=START_DATE,
        schedule="@daily",
        catchup=False,
        tags=["dbt"],
        default_args={"owner": "airflow"},
    ):
      dbt_task = DockerOperator(
          task_id='dbt_run_all',
          image='ghcr.io/dbt-labs/dbt-postgres:1.9.latest',
          command='dbt run',
          force_pull=False, 
          auto_remove=True,
      )
    EOF'  

  - cd /opt/airflow
  - sudo curl -LfO https://airflow.apache.org/docs/apache-airflow/3.1.0/docker-compose.yaml
  - echo "AIRFLOW_UID=$(id -u airflow)" | sudo tee .env
  - echo "_AIRFLOW_WWW_USER_USERNAME=${airflow_username}" | sudo tee -a .env
  - echo "_AIRFLOW_WWW_USER_PASSWORD=${airflow_password}" | sudo tee -a .env
  - sudo chown airflow:airflow .env
  - sudo docker-compose pull
  - sudo -u airflow -H bash -c "docker-compose up"

final_message: "The Airflow EC2 instance is ready."
